{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Word Count\n",
    "Counting the number of occurances of words in a text is one of the most popular first eercises when learning Map-Reduce Programming. It is the equivalent to `Hello World!` in regular programming.\n",
    "\n",
    "We will do it two way, a simpler way where sorting is done after the RDD is collected, and a more sparky way, where the sorting is also done using an RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../Data/Moby-Dick.txt\r\n"
     ]
    }
   ],
   "source": [
    "# First, check that the text file is where we expect it to be\n",
    "%ls ../../Data/Moby-Dick.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the text file into an RDD\n",
    "Note that, as execution is Lazy, this does not necessarily mean that actual reading of the file content has occured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.23 ms, sys: 1.18 ms, total: 2.41 ms\n",
      "Wall time: 26.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "text_file = sc.textFile(u'../../Data/Moby-Dick.txt')\n",
    "type(text_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count the words\n",
    "Next, we count the number of words that occured in the text. Again, this is only setting the plan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.1 ms, sys: 4.6 ms, total: 17.7 ms\n",
      "Wall time: 27.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "counts = text_file.flatMap(lambda line: line.split(\" \")) \\\n",
    "             .map(lambda word: (word, 1)) \\\n",
    "             .reduceByKey(lambda a, b: a + b)\n",
    "type(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Have a look a the execution plan\n",
    "Note that the earliest node in the dependency graph is the file `../../Data/Moby-Dick.txt`. It is possible that that even the first element in that file has not yet been read!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2) PythonRDD[83] at RDD at PythonRDD.scala:43 []\n",
      " |  MapPartitionsRDD[82] at mapPartitions at PythonRDD.scala:374 []\n",
      " |  ShuffledRDD[81] at partitionBy at NativeMethodAccessorImpl.java:-2 []\n",
      " +-(2) PairwiseRDD[80] at reduceByKey at <timed exec>:1 []\n",
      "    |  PythonRDD[79] at reduceByKey at <timed exec>:1 []\n",
      "    |  MapPartitionsRDD[78] at textFile at NativeMethodAccessorImpl.java:-2 []\n",
      "    |  ../../Data/Moby-Dick.txt HadoopRDD[77] at textFile at NativeMethodAccessorImpl.java:-2 []\n"
     ]
    }
   ],
   "source": [
    "print counts.toDebugString()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count!\n",
    "Finally we count the number of times each word has occured.\n",
    "Note that this cell, finaally, the Lazy execution model finally performs some actual work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count=33783.000000, sum=219480.000000, mean=6.496759\n",
      "CPU times: user 12 ms, sys: 4.37 ms, total: 16.4 ms\n",
      "Wall time: 121 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Count=counts.count()\n",
    "Sum=counts.map(lambda (w,i): i).reduce(lambda x,y:x+y)\n",
    "print 'count=%f, sum=%f, mean=%f'%(Count,Sum,float(Sum)/Count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count=33782.000000, sum=219480.000000, mean=6.496951\n",
      "CPU times: user 12.4 ms, sys: 4.35 ms, total: 16.8 ms\n",
      "Wall time: 228 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def SUM(x,y):\n",
    "    return x+y\n",
    "Count=counts.count()\n",
    "Sum=counts.map(lambda (w,i): i).reduce(SUM)\n",
    "print 'count=%f, sum=%f, mean=%f'%(Count,Sum,float(Sum)/Count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect the `Sum` RDD into the driver node\n",
    "This also takes significant work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.5 ms, sys: 3.96 ms, total: 24.4 ms\n",
      "Wall time: 98.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "C=counts.collect()\n",
    "type(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort \n",
    "Now that we have collected the Sum RDD into the driver node, we no longer rely on Spark. The following two cells\n",
    "are simple python commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "most common words [(u'I', 1724), (u'his', 2415), (u'that', 2693), (u'in', 3878), (u'', 4347), (u'to', 4510), (u'a', 4533), (u'and', 5951), (u'of', 6587), (u'the', 13766)]\n",
      "Least common words [(u'funereal', 1), (u'unscientific', 1), (u'lime-stone,', 1), (u'shouted,', 1), (u'pitch-pot,', 1), (u'cod-liver', 1), (u'prices', 1), (u'prefix', 1), (u'boots.\"', 1), (u'slew.', 1)]\n"
     ]
    }
   ],
   "source": [
    "C.sort(key=lambda x:x[1])\n",
    "print 'most common words',C[-10:]\n",
    "print 'Least common words',C[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the mean number of occurances per word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count2=33783.000000, sum2=219480.000000, mean2=6.496759\n"
     ]
    }
   ],
   "source": [
    "Count2=len(C)\n",
    "Sum2=sum([i for w,i in C])\n",
    "print 'count2=%f, sum2=%f, mean2=%f'%(Count2,Sum2,float(Sum2)/Count2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Count in Pure Spark\n",
    "We now show how to perform word count, including sorting, using RDDs, returning to the driver node just the top 10 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 37 µs, sys: 11 µs, total: 48 µs\n",
      "Wall time: 43.2 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "RDD=text_file.flatMap(lambda x: x.split(' '))\\\n",
    "    .filter(lambda x: x!='')\\\n",
    "    .map(lambda word: (word,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.31 ms, sys: 2.61 ms, total: 9.92 ms\n",
      "Wall time: 14.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "RDD1=RDD.reduceByKey(lambda x,y:x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23 µs, sys: 5 µs, total: 28 µs\n",
      "Wall time: 30 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "RDD2=RDD1.map(lambda (c,v):(v,c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.2 ms, sys: 5.44 ms, total: 23.7 ms\n",
      "Wall time: 452 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "RDD3=RDD2.sortByKey(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2) PythonRDD[135] at RDD at PythonRDD.scala:43 []\n",
      " |  MapPartitionsRDD[134] at mapPartitions at PythonRDD.scala:374 []\n",
      " |  ShuffledRDD[133] at partitionBy at null:-1 []\n",
      " +-(2) PairwiseRDD[132] at sortByKey at <timed exec>:1 []\n",
      "    |  PythonRDD[131] at sortByKey at <timed exec>:1 []\n",
      "    |  MapPartitionsRDD[128] at mapPartitions at PythonRDD.scala:374 []\n",
      "    |  ShuffledRDD[127] at partitionBy at null:-1 []\n",
      "    +-(2) PairwiseRDD[126] at reduceByKey at <timed exec>:1 []\n",
      "       |  PythonRDD[125] at reduceByKey at <timed exec>:1 []\n",
      "       |  MapPartitionsRDD[78] at textFile at NativeMethodAccessorImpl.java:-2 []\n",
      "       |  ../../Data/Moby-Dick.txt HadoopRDD[77] at textFile at NativeMethodAccessorImpl.java:-2 []\n"
     ]
    }
   ],
   "source": [
    "print RDD3.toDebugString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.34 ms, sys: 2.17 ms, total: 6.52 ms\n",
      "Wall time: 126 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(13766, u'the'),\n",
       " (6587, u'of'),\n",
       " (5951, u'and'),\n",
       " (4533, u'a'),\n",
       " (4510, u'to'),\n",
       " (3878, u'in'),\n",
       " (2693, u'that'),\n",
       " (2415, u'his'),\n",
       " (1724, u'I'),\n",
       " (1692, u'with')]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "RDD3.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
